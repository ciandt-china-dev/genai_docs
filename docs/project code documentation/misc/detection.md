## ClassDef BoundingBoxDataset
**BoundingBoxDataset**: The function of BoundingBoxDataset is 画像から指定されたバウンディングボックス領域を抽出し、指定されたサイズにリサイズすることです。

**attributes**: The attributes of this Class.
· org_img: 元の画像を保持します。
· scale_wh: 幅と高さのスケールファクターを保持します。
· boundbox: バウンディングボックスのリストを保持します。
· output_size: 出力画像のサイズを指定します。

**Code Description**: BoundingBoxDatasetクラスは、画像からバウンディングボックス領域を抽出し、指定されたサイズにリサイズするためのデータセットを提供します。このクラスは、画像処理や物体検出の前処理として使用されます。`__init__`メソッドでは、元の画像、スケールファクター、バウンディングボックスのリスト、および出力サイズを初期化します。`__getitem__`メソッドは、指定されたインデックスのバウンディングボックスを取得し、その領域を元の画像から切り出してリサイズします。リサイズされた画像は、正規化されて返されます。`__len__`メソッドは、バウンディングボックスの数を返します。

このクラスは、`misc/detection.py/Detector/_bounding_box`メソッド内で使用されており、バウンディングボックス領域を抽出して分類器モデルに入力するためのデータセットとして機能します。`torch.utils.data.DataLoader`を使用して、バッチ処理を行い、効率的にデータを供給します。

**Note**: 使用する際には、元の画像とバウンディングボックスの座標が正しく設定されていることを確認してください。また、出力サイズは適切に設定する必要があります。

**Output Example**: 
```
array([[[0.00392157, 0.00392157, ..., 0.00392157],
        [0.00392157, 0.00392157, ..., 0.00392157],
        ...,
        [0.00392157, 0.00392157, ..., 0.00392157]]], dtype=float32)
```
この出力例は、リサイズされ正規化された画像データを示しています。
### FunctionDef __init__(self, org_img, scale_wh, boundbox, output_size)
**__init__**: The function of __init__ is to initialize a new instance of the BoundingBoxDataset class with the given parameters.

**parameters**: The parameters of this Function.
· org_img: 元の画像を表すパラメータです。この画像は、バウンディングボックスの処理に使用されます。
· scale_wh: 画像の幅と高さのスケールを指定するパラメータです。バウンディングボックスのスケーリングに使用されます。
· boundbox: バウンディングボックスの情報を含むパラメータです。通常、座標やサイズの情報を含みます。
· output_size: 出力画像のサイズを指定するオプションのパラメータです。デフォルトは(56, 56)です。

**Code Description**: この関数は、BoundingBoxDatasetクラスの新しいインスタンスを初期化します。`org_img`は処理対象の元の画像を指定し、`scale_wh`は画像のスケールを指定します。`boundbox`はバウンディングボックスの情報を提供し、`output_size`は出力される画像のサイズを指定します。これらのパラメータは、クラスのインスタンス変数として保存され、後続の処理で使用されます。

**Note**: この関数を使用する際は、`org_img`に有効な画像データを渡し、`scale_wh`と`boundbox`に適切なスケールとバウンディングボックスの情報を提供する必要があります。また、`output_size`は必要に応じて変更可能ですが、デフォルト値が設定されています。
***
### FunctionDef __getitem__(self, idx)
**__getitem__**: __getitem__の機能は、指定されたインデックスに基づいてバウンディングボックスを取得し、画像を適切にスケーリングおよびクロップして返すことです。

**parameters**: この関数のパラメータ。
· idx: 取得したいバウンディングボックスのインデックス。

**Code Description**: この関数の説明。
この関数は、まず`self.boundbox`から指定された`idx`に対応するバウンディングボックス`bb`を取得します。次に、バウンディングボックスの座標(x1, y1, x2, y2)を2倍にスケーリングします。その後、`self.scale_wh`を使用して幅と高さのスケールを適用し、座標を整数に丸めます。次に、座標が元の画像`self.org_img`の境界内に収まるように調整します。

その後、指定された座標範囲で元の画像をクロップし、もしクロップされた画像のサイズが0であれば、1x1のゼロ行列を作成します。次に、`cv2.resize`を使用してクロップされた画像を`self.output_size`にリサイズし、形状を(1, 高さ, 幅)にリシェイプします。最後に、画像を`np.float32`型に変換し、255で割って正規化したものを返します。

**Note**: コードの使用に関する注意点
- インデックス`idx`は、`self.boundbox`の範囲内である必要があります。
- 出力される画像は、指定された`self.output_size`にリサイズされます。
- クロップされた画像が空の場合、1x1のゼロ行列が返されます。

**Output Example**: コードの返り値の可能な例
- 返される画像は、形状が(1, output_size[1], output_size[0])で、ピクセル値が0から1の範囲に正規化されたnumpy配列です。
***
### FunctionDef __len__(self)
**__len__**: The function of __len__ is BoundingBoxDatasetオブジェクトの長さを返します。

**parameters**: この関数にはパラメータはありません。

**Code Description**: 
この関数は、BoundingBoxDatasetクラスのインスタンスに含まれるバウンディングボックスの数を返します。具体的には、`self.boundbox`という属性の長さを取得し、それを返します。`self.boundbox`は、バウンディングボックスのリストまたはコレクションであると推測されます。この関数を呼び出すことで、データセット内のバウンディングボックスの総数を簡単に知ることができます。

**Note**: 
- この関数は、Pythonの組み込み関数`len()`を使用して、BoundingBoxDatasetオブジェクトの長さを取得する際に自動的に呼び出されます。
- `self.boundbox`が適切に初期化されていることを確認してください。

**Output Example**: 
例えば、`self.boundbox`に5つのバウンディングボックスが含まれている場合、この関数は5を返します。
***
## ClassDef Detector
**Detector**: Detectorの機能は、画像内のテキスト領域を検出し、バウンディングボックスを生成することです。

**attributes**: このクラスの属性。
- use_cuda: CUDAを使用してGPUで計算を行うかどうかを示すブール値。
- word_threshold: 単語の検出に使用されるしきい値。
- class_threshold: クラス分類のしきい値。
- low_gpu_memory: GPUメモリが少ない環境での動作を示すブール値。

**Code Description**: このクラスの説明。
Detectorクラスは、画像からテキスト領域を検出し、バウンディングボックスを生成するための一連のメソッドを提供します。初期化メソッド`__init__`では、CUDAの使用やしきい値の設定を行います。

- `_preprocess`: 画像の前処理を行い、線の検出と重複する線の除去を行います。画像がシンプルな場合は、すべての線をマップとして返し、そうでない場合は、前処理されたヒートマップを返します。
- `_get_class`: 画像をクラスタリングし、クラスマップを生成します。
- `_get_map`: クラスマップから輪郭を検出し、マップを生成します。
- `_filt_map`: 重複するマップをフィルタリングし、最適なマップを選択します。
- `_scale_image`: 画像を指定されたサイズにスケーリングします。
- `_detect1x`, `_detect4x`, `_detect16x`: 画像を異なるスケールで検出し、ヒートマップを生成します。
- `_get_maps`: 画像のスケールに基づいて適切な検出メソッドを選択し、ヒートマップを取得します。
- `_find_best_dpi`: 最適なDPIを見つけるために複数のDPIで検出を試みます。
- `detect_image`: 画像を検出し、バウンディングボックスを生成します。
- `_bounding_box`: クラス分類器を使用してバウンディングボックスを生成します。
- `bounding_box`: 検出された領域に対してバウンディングボックスを生成し、クラス分類を行います。

このクラスは、`ocr_japanease.py`内の`get_ocr`関数から呼び出され、画像ファイルリストに対してOCR処理を行います。`get_ocr`関数は、Detectorクラスを使用して画像内のテキスト領域を検出し、バウンディングボックスを生成します。その後、クラス分類器を使用して各領域のテキストを識別します。

**Note**: このコードを使用する際には、CUDAの設定やモデルファイルの存在を確認する必要があります。また、GPUメモリが少ない環境では、`low_gpu_memory`を`True`に設定することでメモリ使用量を抑えることができます。

**Output Example**: このコードの返り値の可能な例。
- DPI: 画像の解像度に基づいて検出されたDPI値。
- sent_box: 検出されたテキスト領域のバウンディングボックスのリスト。
- gray_img: 処理されたグレースケール画像。
- scale_image: 画像のスケール情報。
- hm_wd: 単語のヒートマップ。
### FunctionDef __init__(self, use_cuda, word_threshold, class_threshold, low_gpu_memory)
**__init__**: The function of __init__ is 初期化メソッドとして、Detectorクラスのインスタンスを生成する際に初期設定を行います。

**parameters**: The parameters of this Function.
· use_cuda: CUDAを使用するかどうかを指定するブール値。デフォルトはTrueです。
· word_threshold: 単語の検出に使用するしきい値を指定する浮動小数点数。デフォルトは0.01です。
· class_threshold: クラスの検出に使用するしきい値を指定する浮動小数点数。デフォルトは0.25です。
· low_gpu_memory: GPUメモリが少ない環境での動作を考慮するかどうかを指定するブール値。デフォルトはFalseです。

**Code Description**: The description of this Function.
この__init__メソッドは、Detectorクラスのインスタンスを生成する際に呼び出され、いくつかの初期設定を行います。`use_cuda`パラメータは、CUDAを使用するかどうかを決定し、GPUを利用した高速な計算を可能にします。`word_threshold`と`class_threshold`は、それぞれ単語とクラスの検出におけるしきい値を設定し、検出の感度を調整します。`low_gpu_memory`は、GPUメモリが限られている環境での動作を考慮するための設定で、Trueに設定するとメモリ使用量を抑えるための最適化が行われます。

**Note**: Points to note about the use of the code
- `use_cuda`をTrueに設定する場合、CUDAが利用可能な環境であることを確認してください。
- `word_threshold`と`class_threshold`の値を調整することで、検出の精度や感度をカスタマイズできます。
- `low_gpu_memory`をTrueに設定すると、パフォーマンスが低下する可能性があるため、必要に応じて使用してください。
***
### FunctionDef _preprocess(self, hm_wd, hm_sent, hm_pos, simple_mode_lines, hm_dup, high_threshold, low_threshold)
**_preprocess**: _preprocess関数の機能は、ヒートマップデータを処理し、画像内の線分を検出してフィルタリングすることです。

**parameters**: この関数のパラメータ。
· hm_wd: 単語レベルのヒートマップ。
· hm_sent: 文レベルのヒートマップ。
· hm_pos: 位置情報を含むヒートマップ。
· simple_mode_lines: 簡易モードで処理する際の最大線分数（デフォルトは5）。
· hm_dup: ヒートマップの重複係数（デフォルトは2.5）。
· high_threshold: 高いスコアを持つピクセルの閾値（デフォルトは0.5）。
· low_threshold: 低いスコアを持つピクセルの閾値（デフォルトは0.15）。

**Code Description**: _preprocess関数は、まず文レベルのヒートマップ(hm_sent)を255倍してクリップし、HoughLinesPメソッドを用いて線分を検出します。検出された線分は、CenterLineクラスを用いて中心線として評価され、スコアに基づいてソートされます。次に、重複する線分や交差する線分を削除するために、containメソッドとcrossメソッドを使用して非最大抑制(NMS)を行います。

簡易モードで処理する場合、線分を描画したマップを返します。それ以外の場合、線分を描画した後、ヒートマップを重複係数でフィルタリングし、指定された閾値に基づいて前処理を行います。最終的に、処理されたヒートマップを返します。

この関数は、detect_imageメソッドから呼び出され、画像内の文の境界を検出するための前処理として機能します。detect_imageメソッドでは、_preprocess関数を用いてヒートマップを処理し、文の境界ボックスを生成します。

**Note**: 使用する際には、ヒートマップの形状が一致していることを確認してください。また、線分のスコアはヒートマップの値に依存するため、ヒートマップの前処理が重要です。

**Output Example**: 簡易モードの場合、線分を描画したマップのリストが返されます。それ以外の場合、前処理されたヒートマップが返されます。具体的な出力例はありませんが、線分の検出とフィルタリングが行われた後のヒートマップが得られます。
***
### FunctionDef _get_class(self, im, size)
**_get_class**: _get_classの機能は、画像データをクラスタリングし、クラスマップを生成することです。

**parameters**: この関数のパラメータ。
· im: クラスタリング対象の入力画像データ。
· size: 画像をリサイズする際の目標サイズ（デフォルトは128）。

**Code Description**: この関数は、入力画像データをクラスタリングし、クラスマップを生成します。まず、入力画像の最小値と最大値を取得し、これを用いて画像を正規化します。次に、画像を指定されたサイズにリサイズします。リサイズされた画像の中で、画素値が0.01を超える座標をリストに追加します。この座標リストを用いて、OPTICSクラスタリングアルゴリズムを適用し、クラスタを識別します。クラスタリング結果を用いて、新しいクラスマップを生成し、元の画像サイズにリサイズして返します。

この関数は、`detect_image`メソッド内で呼び出され、文書画像のセグメンテーションを行うために使用されます。特に、`hm_sent_preprocessed`が存在する場合に、クラスマップを生成し、さらに処理を行うために利用されます。

**Note**: 使用する際には、入力画像が適切に正規化されていることを確認してください。また、クラスタリングの結果は、入力データの特性に依存するため、期待する結果が得られない場合は、パラメータの調整が必要です。

**Output Example**: 関数の返り値は、入力画像と同じ寸法を持つ整数型の2次元配列で、各要素はクラスタのクラスを示します。例えば、`[[0, 1, 1], [0, 0, 2], [2, 2, 2]]`のような形式になります。
***
### FunctionDef _get_map(self, clz_map)
**_get_map**: _get_mapの機能は、クラスマップから輪郭を抽出し、各クラスのマップを生成することです。

**parameters**: この関数のパラメータ。
· clz_map: クラスマップを表すnumpy配列。各要素はクラスのラベルを示します。

**Code Description**: この関数は、与えられたクラスマップ(clz_map)から各クラスの輪郭を抽出し、それを基にしたバイナリマップを生成します。具体的には、以下の手順で処理を行います。

1. `all_map`というリストを初期化し、最終的にすべてのクラスのマップを格納します。
2. `clz_map`内の最大クラスラベルを取得し、1からその最大値までの範囲でループを実行します。
3. 各クラスラベルに対して、`clz_wd`というゼロで初期化された配列を作成し、`clz_map`内で現在のクラスラベルに一致する位置を見つけます。
4. 一致する位置に対して、`clz_wd`の該当する要素を255に設定します。
5. `cv2.findContours`を使用して、`clz_wd`から外部輪郭を抽出します。
6. 各輪郭に対して、最小外接矩形を計算し、その矩形の頂点を取得して描画します。
7. 描画されたマップを`all_map`に追加します。
8. 最終的に、すべてのクラスのマップを含む`all_map`を返します。

この関数は、`detect_image`メソッド内で使用されており、クラスマップから抽出された輪郭を基に、文の境界ボックスを生成するための前処理として機能しています。

**Note**: この関数は、OpenCVの関数を使用して輪郭を抽出し、描画するため、OpenCVがインストールされている必要があります。また、入力されるクラスマップは、整数ラベルで構成されている必要があります。

**Output Example**: この関数の返り値は、各クラスの輪郭が描画されたバイナリマップのリストです。例えば、クラスが3つある場合、`all_map`には3つのバイナリマップが含まれます。それぞれのマップは、対応するクラスの領域が255で示され、その他の領域が0で示されます。
***
### FunctionDef _filt_map(self, all_map)
**_filt_map**: _filt_mapの機能は、与えられたマップのリストをフィルタリングし、特定の条件に基づいて不要なマップを削除することです。

**parameters**: この関数のパラメータ。
· all_map: 処理対象のマップのリスト。

**Code Description**: この関数の説明。
_filt_map関数は、入力として与えられたマップのリスト（all_map）をフィルタリングし、特定の条件を満たすマップを削除します。まず、二重ループを使用して、各マップペアを比較します。もし、あるマップm1の非ゼロ要素が他のマップm2のすべての要素に含まれる場合、そのインデックスをdindxリストに追加します。次に、dindxに含まれないマップについて、再度二重ループを行い、重複する非ゼロ要素を持つマップペアを見つけます。この場合、要素の合計が大きい方のマップに基づいて、重複する要素をゼロに設定します。最後に、フィルタリングされたマップを合計値の降順にソートして返します。

この関数は、detect_imageメソッド内で使用されており、画像から検出されたマップをフィルタリングするために利用されています。これにより、重複する情報を持つマップが削除され、効率的な検出結果が得られます。

**Note**: このコードを使用する際の注意点
- 入力されるマップは、NumPy配列として処理されることを前提としています。
- マップの要素は数値であり、ゼロと非ゼロの区別が重要です。

**Output Example**: このコードの返り値の可能な例
- フィルタリングされたマップのNumPy配列。例えば、[[0, 1, 0], [1, 0, 1]]のような形式。
***
### FunctionDef _scale_image(self, img, long_size)
**_scale_image**: The function of _scale_image is 画像を指定された長辺サイズにスケーリングすることです。

**parameters**: この関数のパラメータ。
- img: スケーリング対象の画像。通常はnumpy配列として表現されます。
- long_size: 画像の長辺をスケーリングするための目標サイズ。

**Code Description**: この関数は、入力された画像の長辺を指定されたサイズにスケーリングします。まず、画像の縦横のサイズを比較し、長辺を決定します。次に、長辺を指定されたサイズにスケーリングするためのスケールファクターを計算します。縦横比を維持するために、短辺も適切にスケーリングされます。最終的に、OpenCVの`cv2.resize`関数を使用して、指定されたサイズに画像をリサイズします。この際、補間方法として`cv2.INTER_CUBIC`を使用します。

この関数は、`_get_maps`メソッド内で呼び出され、画像を適切なサイズにスケーリングし、後続の画像処理ステップで使用されます。特に、`_get_maps`では、スケーリングされた画像がさらに処理され、検出モデルに入力されます。

**Note**: この関数を使用する際は、入力画像がnumpy配列であることを確認してください。また、`long_size`は画像の長辺に対する目標サイズであり、適切に設定する必要があります。

**Output Example**: この関数の戻り値は、指定されたサイズにスケーリングされた画像です。例えば、入力画像が1000x500ピクセルで、`long_size`が500の場合、戻り値は500x250ピクセルの画像になります。
***
### FunctionDef _detect1x(self, detector_model, gray_img_scaled)
**_detect1x**: _detect1xの機能は、指定された検出モデルを使用してスケーリングされたグレースケール画像から特徴マップを生成することです。

**parameters**: この関数のパラメータ。
- detector_model: 特徴マップを生成するために使用される検出モデル。
- gray_img_scaled: スケーリングされたグレースケール画像。

**Code Description**: この関数は、まず512x512のゼロで初期化された配列を作成し、入力されたグレースケール画像をこの配列に配置します。次に、画像データを0から1の範囲にクリップし、float32型に変換します。このデータはPyTorchのテンソルに変換されます。`use_cuda`がTrueの場合、データとモデルはCUDAを使用してGPUに転送されます。モデルは評価モードに設定され、テンソルを入力として予測が行われます。出力は、`hm_wd`、`hm_sent`、`hm_pos`という3つの特徴マップとして取得され、それぞれが256x256の形状にリシェイプされます。最後に、使用したテンソルと出力を削除し、必要に応じてCUDAのキャッシュをクリアします。

この関数は、`_get_maps`関数から呼び出され、画像のサイズに応じて適切な特徴マップを生成するために使用されます。具体的には、画像のサイズが512の場合にこの関数が呼び出され、特徴マップが生成されます。

**Note**: 
- `use_cuda`がTrueの場合、CUDAを使用して計算が行われるため、GPUが必要です。
- 入力画像は512x512にスケーリングされる必要があります。

**Output Example**: 
- hm_wd: 256x256のnumpy配列。
- hm_sent: 256x256のnumpy配列。
- hm_pos: 2x256x256のnumpy配列。
***
### FunctionDef _detect4x(self, detector_model, gray_img_scaled)
**_detect4x**: _detect4xの機能は、入力された画像を4つのセグメントに分割し、それぞれのセグメントに対して検出モデルを適用して特徴マップを生成することです。

**parameters**: この関数のパラメータ。
- detector_model: 検出に使用されるモデル。PyTorchのモデルである必要があります。
- gray_img_scaled: スケーリングされたグレースケール画像。サイズは1024x1024であることが期待されます。

**Code Description**: この関数の説明。
_detect4x関数は、入力された1024x1024のグレースケール画像を4つの512x512のセグメントに分割します。これらのセグメントは、テンポラリ配列`tmp`に配置され、さらに`im`配列に格納されます。次に、これらのセグメントは0から1の範囲に正規化され、PyTorchテンソルに変換されます。

関数は、GPUメモリの使用状況とCUDAの使用可否に応じて、異なる処理を行います。低GPUメモリモードでない場合、またはCUDAが使用できない場合、4つのセグメントを一度にモデルに入力し、特徴マップを取得します。そうでない場合は、各セグメントを個別に処理します。

各セグメントから得られた特徴マップは、`org_hm_wd`、`org_hm_sent`、`org_of_size`として保存されます。これらのマップは、最終的に512x512の`hm_wd`、`hm_sent`、および2x512x512の`hm_pos`に統合され、関数の出力として返されます。

この関数は、呼び出し元の_get_maps関数内で、画像サイズが1024の場合に呼び出されます。_get_maps関数は、画像のサイズに応じて適切な検出関数を選択し、_detect4xはその中で1024サイズの画像に対して使用されます。

**Note**: このコードを使用する際の注意点
- 入力画像は1024x1024にスケーリングされている必要があります。
- CUDAを使用する場合、適切に設定されていることを確認してください。
- GPUメモリの制約に注意し、必要に応じて低メモリモードを使用してください。

**Output Example**: このコードの返り値の可能な例
- hm_wd: 512x512の配列
- hm_sent: 512x512の配列
- hm_pos: 2x512x512の配列

これらの出力は、画像の各セグメントに対する検出結果を統合したものであり、画像内の特徴を示します。
***
### FunctionDef _detect16x(self, detector_model, gray_img_scaled)
**_detect16x**: _detect16xの機能は、2048x2048のスケールで入力画像を処理し、検出モデルを使用してヒートマップを生成することです。

**parameters**: この関数のパラメータ。
- detector_model: 使用する検出モデル。PyTorchのモデルであることが期待されます。
- gray_img_scaled: スケールされたグレースケール画像。サイズは2048x2048である必要があります。

**Code Description**: この関数は、与えられたグレースケール画像を2048x2048のテンポラリ配列に配置し、検出モデルを使用してヒートマップを生成します。まず、入力画像をテンポラリ配列にコピーし、必要に応じてCUDAを使用してモデルをGPU上で実行します。次に、画像を4つの512x512のチャンクに分割し、それぞれをモデルに入力します。モデルの出力は、ヒートマップとオフセットサイズとして取得され、最終的なヒートマップに組み込まれます。

この関数は、プロジェクト内で_get_maps関数から呼び出されており、画像のサイズに応じて適切なスケールで検出を行います。_get_maps関数は、画像のDPIや最小単語サイズに基づいて、_detect16xを含む適切な検出関数を選択します。

**Note**: CUDAを使用する場合、メモリ管理に注意が必要です。特に、低GPUメモリモードでは、各チャンクを個別に処理する必要があります。また、torch.no_grad()を使用して、勾配計算を無効にすることでメモリ使用量を削減しています。

**Output Example**: 関数の戻り値は3つのヒートマップです。
- hm_wd: 単語検出のヒートマップ
- hm_sent: センテンス検出のヒートマップ
- hm_pos: ポジションオフセットのヒートマップ

これらのヒートマップは、サイズ1024x1024であり、画像内のテキスト領域の検出に使用されます。
***
### FunctionDef _get_maps(self, detector_model, gray_img, dpi, min_word_size_cm)
**_get_maps**: _get_mapsの機能は、指定された画像から特徴マップを生成することです。

**parameters**: この関数のパラメータ。
- detector_model: 特徴マップを生成するために使用される検出モデル。
- gray_img: 処理対象のグレースケール画像。
- dpi: 画像の解像度を示すドットパーインチ（DPI）。
- min_word_size_cm: 最小単語サイズをセンチメートルで指定。

**Code Description**: _get_maps関数は、入力されたグレースケール画像のサイズとDPIに基づいて、適切な検出サイズを決定し、画像をスケーリングします。DPIが0の場合、画像の長辺に基づいて検出サイズを決定し、DPIが指定されている場合は、インチサイズからピクセルサイズを計算して検出サイズを決定します。画像は、`_scale_image`関数を使用してスケーリングされ、指定された検出サイズに合わせてゼロパディングされます。

スケーリングされた画像は、検出モデルに入力され、画像サイズに応じて`_detect1x`、`_detect4x`、または`_detect16x`関数が呼び出されます。これらの関数は、それぞれ512x512、1024x1024、2048x2048の画像サイズに対応し、特徴マップを生成します。生成された特徴マップは、ヒートマップとして返されます。

この関数は、`_find_best_dpi`や`detect_image`関数から呼び出され、画像のDPIやサイズに基づいて最適な特徴マップを生成するために使用されます。特に、`detect_image`関数では、画像のDPIが指定されている場合は直接この関数を呼び出し、DPIが負の場合は`_find_best_dpi`を通じて最適なDPIを見つけた後に呼び出されます。

**Note**: 
- 入力画像はnumpy配列として提供される必要があります。
- DPIが0の場合、画像の長辺に基づいて検出サイズが決定されます。
- CUDAを使用する場合、適切に設定されていることを確認してください。

**Output Example**: 
- pix_image: スケーリングされた画像。
- scale_image: スケールファクターを示すタプル。
- hm_wd: 単語検出のヒートマップ。
- hm_sent: センテンス検出のヒートマップ。
- hm_pos: ポジションオフセットのヒートマップ。
***
### FunctionDef _find_best_dpi(self, detector_model, gray_img, dpi, min_word_size_cm)
**_find_best_dpi**: _find_best_dpiの機能は、画像の最適なDPI（ドットパーインチ）を見つけることです。

**parameters**: この関数のパラメータ。
- detector_model: 特徴マップを生成するために使用される検出モデル。
- gray_img: 処理対象のグレースケール画像。
- dpi: 画像の解像度を示すドットパーインチ（DPI）。
- min_word_size_cm: 最小単語サイズをセンチメートルで指定。

**Code Description**: _find_best_dpi関数は、指定されたグレースケール画像に対して最適なDPIを見つけるために使用されます。この関数は、72、100、150、200、300の5つの異なるDPIでテストを行い、それぞれのDPIでの特徴マップを生成します。生成された特徴マップの中で、特定の閾値を超えるピクセルの割合が最も高いDPIを選択します。この割合は、特徴マップのサイズに対する閾値を超えるピクセルの割合として計算されます。最も適したDPIとそのDPIでの特徴マップを返します。

この関数は、detect_image関数から呼び出され、画像のDPIが負の場合に最適なDPIを見つけるために使用されます。detect_image関数では、DPIが指定されている場合は直接_get_maps関数を呼び出しますが、DPIが負の場合は_find_best_dpiを通じて最適なDPIを見つけた後に_get_mapsを呼び出します。

**Note**: 
- 入力画像はnumpy配列として提供される必要があります。
- _get_maps関数を使用して特徴マップを生成します。
- 特徴マップの評価には、特定の閾値を超えるピクセルの割合が使用されます。

**Output Example**: 
- 最適なDPI値（例: 150）
- 最適なDPIでの特徴マップ（例: (pix_image, scale_image, hm_wd, hm_sent, hm_pos)）
***
### FunctionDef detect_image(self, detector_model, gray_img, dpi, min_word_size_cm)
**detect_image**: detect_image関数の機能は、指定された画像からテキスト領域を検出し、バウンディングボックスを生成することです。

**parameters**: この関数のパラメータ。
· detector_model: 特徴マップを生成するために使用される検出モデル。
· gray_img: 処理対象のグレースケール画像。
· dpi: 画像の解像度を示すドットパーインチ（DPI）。
· min_word_size_cm: 最小単語サイズをセンチメートルで指定。

**Code Description**: detect_image関数は、指定されたグレースケール画像からテキスト領域を検出するために、いくつかのステップを実行します。まず、`min_word_size_cm`と`dpi`を使用して、単語の最小境界を計算します。次に、DPIが0以上の場合、`_get_maps`関数を呼び出して、画像から特徴マップを生成します。DPIが負の場合は、`_find_best_dpi`関数を使用して最適なDPIを見つけ、そのDPIで特徴マップを生成します。

生成されたヒートマップデータは、`_preprocess`関数を使用して前処理されます。この前処理により、文レベルのヒートマップがフィルタリングされ、クラスマップが生成されます。クラスマップは、`_get_class`関数を使用してクラスタリングされ、`_get_map`関数で各クラスのマップが生成されます。これらのマップは、`_filt_map`関数でフィルタリングされ、不要なマップが削除されます。

最終的に、`SentenceBox`クラスを使用して、各クラスマップからバウンディングボックスが生成されます。これにより、画像内のテキスト領域が検出され、バウンディングボックスとして返されます。この関数は、`ocr_japanease.py`内の`get_ocr`関数から呼び出され、画像ファイルリストに対してOCR処理を行う際に使用されます。

**Note**: 
- 入力画像はnumpy配列として提供される必要があります。
- DPIが負の場合、最適なDPIを見つけるために`_find_best_dpi`関数が使用されます。
- バウンディングボックスの生成には、`SentenceBox`クラスが使用されます。

**Output Example**: 
- dpi: 使用されたDPI値。
- sent_box: 検出されたバウンディングボックスのリスト。
- gray_img: 処理されたグレースケール画像。
- scale_image: スケールファクターを示すタプル。
- hm_wd: 単語検出のヒートマップ。
***
### FunctionDef _bounding_box(self, classifier_model, gray_img, scale_image, boundings, batch_size_classifier, num_workers)
**_bounding_box**: The function of _bounding_box is バウンディングボックスの領域を抽出し、分類器モデルを使用して予測を行うことです。

**parameters**: The parameters of this Function.
· classifier_model: 分類器モデルを指定します。
· gray_img: グレースケール画像を指定します。
· scale_image: 画像のスケールファクターを指定します。
· boundings: バウンディングボックスのリストを指定します。
· batch_size_classifier: 分類器のバッチサイズを指定します。
· num_workers: データローダーのワーカー数を指定します。

**Code Description**: 
この関数は、`BoundingBoxDataset`クラスを使用して、指定されたグレースケール画像からバウンディングボックス領域を抽出し、指定されたスケールでリサイズします。`BoundingBoxDataset`は、画像からバウンディングボックス領域を抽出し、指定されたサイズにリサイズするためのデータセットを提供します。

その後、`torch.utils.data.DataLoader`を使用してデータをバッチ処理し、効率的に分類器モデルに供給します。`torch.nn.DataParallel`を用いてモデルを並列化し、GPUを使用して予測を行います。予測結果はソフトマックス関数を用いて正規化され、各バウンディングボックスに対して予測結果が設定されます。

この関数は、`bounding_box`メソッド内で呼び出され、バウンディングボックスの領域を抽出して分類器モデルに入力するために使用されます。`bounding_box`メソッドは、バウンディングボックスの予測結果に基づいて追加のバウンディングボックスを生成し、再度`_bounding_box`を呼び出して予測を行います。

**Note**: 使用する際には、GPUメモリの使用状況に注意し、必要に応じて`torch.cuda.empty_cache()`を使用してキャッシュをクリアしてください。また、バウンディングボックスの座標が正しく設定されていることを確認する必要があります。
***
### FunctionDef bounding_box(self, classifier_model, detection, batch_size_classifier, num_workers, repeat_box)
**bounding_box**: The function of bounding_box is バウンディングボックスを生成し、分類器モデルを用いて予測を行うことです。

**parameters**: The parameters of this Function.
· classifier_model: 使用する分類器モデル。
· detection: 検出結果のタプル（dpi, sent_box, gray_img, scale_image, hm_wd）。
· batch_size_classifier: 分類器のバッチサイズ（デフォルトは64）。
· num_workers: データローダーのワーカー数（デフォルトは2）。
· repeat_box: バウンディングボックスの再評価回数（デフォルトは1）。

**Code Description**: bounding_box関数は、画像内のテキスト領域を検出し、バウンディングボックスを生成して分類器モデルを用いてそれらを評価します。まず、検出結果からdpi、sent_box、gray_img、scale_image、hm_wdを取得します。各sent_boxに対して、文のインデックスと検出スコアを設定します。すべてのバウンディングボックスを集約し、_bounding_boxメソッドを呼び出して分類器モデルで予測を行います。

次に、repeat_boxの回数だけ追加のバウンディングボックスを生成し、再度予測を行います。具体的には、各バウンディングボックスの予測結果に基づいて、横並びまたは縦並びの追加バウンディングボックスを生成します。これらの追加バウンディングボックスに対しても、_bounding_boxメソッドを用いて予測を行います。

最終的に、予測スコアがclass_thresholdを超えるバウンディングボックスのみを返します。この関数は、ocr_japanease.pyのget_ocr関数から呼び出され、画像内のテキスト領域を検出し、分類するために使用されます。

**Note**: 使用時には、GPUメモリの使用状況に応じてbatch_size_classifierを調整する必要があります。また、バウンディングボックスの座標が画像の境界を超えないように注意が必要です。

**Output Example**: 
- バウンディングボックスのリスト: `[BoundingBox(x1, y1, x2, y2), ...]`
- 各バウンディングボックスには、検出スコアや予測スコアが設定されます。
***
